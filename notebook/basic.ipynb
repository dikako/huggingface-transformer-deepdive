{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sentence = \"I am learning Machine Learning\"\n",
    "\n",
    "encoded_sentence = tokenizer(sentence)\n",
    "encoded_ids = encoded_sentence[\"input_ids\"]\n",
    "print(\"Input Ids:\", encoded_ids)\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(encoded_ids))\n",
    "\n",
    "decode_string = tokenizer.decode(encoded_ids)\n",
    "print(\"Decoded String:\", decode_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Results\n",
    "\n",
    "**Input Ids:** [101, 1045, 2572, 4083, 3698, 4083, 102]\n",
    "\n",
    "**Tokens:** ['[CLS]', 'i', 'am', 'learning', 'machine', 'learning', '[SEP]']\n",
    "\n",
    "**Decoded String:** [CLS] i am learning machine learning [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform following NLP operation using HuggingFace library with Pipeline functions\n",
    "\n",
    "1. Sentiment analysis\n",
    "2. Fill Mask\n",
    "3. NER\n",
    "4. Q&A\n",
    "5. Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "positive_sentence = \"I am learning Machine Learning after a long time, which is great!\"\n",
    "positive_result = classifier(positive_sentence)\n",
    "print(\"Sentiment Positive\")\n",
    "print(\"Sentences:\", positive_sentence)\n",
    "print(\"Sentiment:\", positive_result)\n",
    "\n",
    "negative_sentence = \"I am learning Machine Learning but its not working out for me\"\n",
    "negative_result = classifier(negative_sentence)\n",
    "print(\"Sentiment Negative\")\n",
    "print(\"Sentences:\", negative_sentence)\n",
    "print(\"Sentiment:\", negative_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Results\n",
    "\n",
    "#### Sentiment Positive\n",
    "\n",
    "**Sentences:** I am learning Machine Learning after a long time, which is great!\n",
    "\n",
    "**Sentiment:** [{'label': 'POSITIVE', 'score': 0.9997515082359314}]\n",
    "\n",
    "#### Sentiment Negative\n",
    "\n",
    "**Sentences:** I am learning Machine Learning but its not working out for me\n",
    "**Sentiment:** [{'label': 'NEGATIVE', 'score': 0.9995772242546082}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fill Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"distilbert/distilroberta-base\")\n",
    "\n",
    "fill_mask_sentence = \"I am learning <mask> today, make me can cook spicy food\"\n",
    "fill_mask_result = fill_mask(fill_mask_sentence)\n",
    "print(\"Use default model: distilbert/distilroberta-base\")\n",
    "print(\"Fill Mask Sentence:\", fill_mask_sentence)\n",
    "print(\"Fill Mask Result:\", fill_mask_result)\n",
    "\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "fill_mask_sentence = \"I am learning [MASK] today, make me can cook spicy food\"\n",
    "fill_mask_result = fill_mask(fill_mask_sentence)\n",
    "print(\"Use default model: bert-base-uncased\")\n",
    "print(\"Fill Mask Sentence:\", fill_mask_sentence)\n",
    "print(\"Fill Mask Result:\", fill_mask_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouped_entities=False (default)\n",
      "Sentence: My name is Dika and I work as a software engineer.\n",
      "Named Entity Recognition Result: [{'entity': 'I-PER', 'score': np.float32(0.9990803), 'index': 4, 'word': 'Di', 'start': 11, 'end': 13}, {'entity': 'I-PER', 'score': np.float32(0.9972364), 'index': 5, 'word': '##ka', 'start': 13, 'end': 15}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouped_entities=False (default)\n",
      "Sentence: My name is Dika and I work as a software engineer.\n",
      "Named Entity Recognition Result: [{'entity_group': 'PER', 'score': np.float32(0.99815834), 'word': 'Dika', 'start': 11, 'end': 15}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fransiskusandikasetiawan/Documents/rnd/ai/huggingface/py3.11.3/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"ner\")\n",
    "\n",
    "sentence = \"My name is Dika and I work as a software engineer.\"\n",
    "\n",
    "result = classifier(sentence)\n",
    "print(\"grouped_entities=False (default)\")\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Named Entity Recognition Result:\", result)\n",
    "\n",
    "classifier = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "result = classifier(sentence)\n",
    "print(\"grouped_entities=True\")\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Named Entity Recognition Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Results\n",
    "\n",
    "#### grouped_entities=False (default)\n",
    "\n",
    "**Sentence:** My name is Dika and I work as a software engineer.\n",
    "\n",
    "**Named Entity Recognition Result:** [{'entity': 'I-PER', 'score': np.float32(0.9990803), 'index': 4, 'word': 'Di', 'start': 11, 'end': 13}, {'entity': 'I-PER', 'score': np.float32(0.9972364), 'index': 5, 'word': '##ka', 'start': 13, 'end': 15}]\n",
    "\n",
    "#### grouped_entities=True\n",
    "\n",
    "**Sentence:** My name is Dika and I work as a software engineer.\n",
    "\n",
    "**Named Entity Recognition Result:** [{'entity_group': 'PER', 'score': np.float32(0.99815834), 'word': 'Dika', 'start': 11, 'end': 15}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
